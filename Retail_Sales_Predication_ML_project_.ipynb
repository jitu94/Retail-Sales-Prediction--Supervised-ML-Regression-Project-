{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jitu94/Retail-Sales-Prediction--Supervised-ML-Regression-Project-/blob/main/Retail_Sales_Predication_ML_project_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual/Team\n",
        "##### **Team Member 1 -**Rishi Gupta\n",
        "##### **Team Member 2 -**Sumana Mondal\n",
        "##### **Team Member 3 -**Jitendra Sonkar\n",
        "##### **Team Member 4 -**Ankit Mishra\n",
        "##### **Team Member 5 -** Mayank Sinha"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset is a live dataset of Roseman Stores. On analsysing this problem we observe that Roseman problem is a regression problem and our primarily goal is to predict the sales figures of Roseman problem. In this Notebook we work on following topics\n",
        "\n",
        "Analysing the Dataset by using Exploratory Data Analysis. Using Exponential Moving Averages analyse Trends and Seasonality in Roseman dataset. Analyse Regression analysis using following prediction analysis, A. Linear Regression Analysis B. Elastic Regression ( Lasso and Ridge Regression). C. Random Forest Regression. d.adaboost and Xgboost).\n",
        "\n",
        "By applying above algorthim we find accuracy of 98% by Xgboost."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.\n",
        "You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.\n",
        "Data Description\n",
        "Rossmann Stores Data.csv - historical data including Sales\n",
        "store.csv - supplemental information about the stores\n",
        "Data fields\n",
        "Most of the fields are self-explanatory.\n",
        "Id - an Id that represents a (Store, Da,,te) duple within the set\n",
        "Store - a unique Id for each store\n",
        "Sales - the turnover for any given day (Dependent Variable)\n",
        "Customers - the number of customers on a given day"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Description**\n",
        "\n",
        "**Rossmann Stores Data.csv - historical data including Sales**\n",
        "\n",
        "**store.csv - supplemental information about the store**\n",
        "\n",
        "Data fields\n",
        "Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
        "\n",
        "**Id** - an Id that represents a (Store, Date) duple within the test set\n",
        "\n",
        "**Store** - a unique Id for each store\n",
        "\n",
        "**Sales** - the turnover for any given day (this is what you are predicting)\n",
        "\n",
        "**Customers** - the number of customers on a given day\n",
        "\n",
        "**Open** - an indicator for whether the store was open: 0 = closed, 1 = open\n",
        "StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
        "\n",
        "**SchoolHoliday** - indicates if the (Store, Date) was affected by the closure of public schools\n",
        "\n",
        "**StoreType** - differentiates between 4 different store models: a, b, c, d\n",
        "\n",
        "**Assortment** - describes an assortment level: a = basic, b = extra, c = extended\n",
        "\n",
        "**CompetitionDistance** - distance in meters to the nearest competitor store\n",
        "\n",
        "**CompetitionOpenSince[Month/Year] **- gives the approximate year and month of the time the nearest competitor was opened\n",
        "\n",
        "**Promo** - indicates whether a store is running a promo on that day\n",
        "\n",
        "**Promo2** - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
        "\n",
        "**Promo2Since[Year/Week]** - describes the year and calendar week when the store started participating in Promo2\n",
        "\n",
        "**PromoInterval** - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store\n"
      ],
      "metadata": {
        "id": "7lHjgaHbaS-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iuREdJEPvyAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import ast \n",
        "import math\n",
        "import random\n",
        "from scipy.stats import skew\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pickle"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset : - Rossmann Dataset - https://drive.google.com/file/d/1RLUf6NEpRg6sefWqt-nyqLDyMEHryxrl/view?usp=share_link\n",
        "\n",
        "Store Dataset :-https://drive.google.com/file/d/1Tu5r9A1Izhf0JabF473mmyj3jGW-RqnB/view?usp=sharing\n"
      ],
      "metadata": {
        "id": "DD60oyUoT5SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rosmann Data\n",
        "database = \"/content/drive/MyDrive/alambetter  eda  capstone project/Rossmann Stores Data (1).csv\"\n",
        "sales_df =pd.read_csv(database)\n",
        "# Store data\n",
        "database = \"/content/drive/MyDrive/alambetter  eda  capstone project/store (1).csv\"\n",
        "store_df =pd.read_csv(database)"
      ],
      "metadata": {
        "id": "Wpf5lJ2AwIyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "sales_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.info()"
      ],
      "metadata": {
        "id": "6_2mfFA-1kx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.tail()"
      ],
      "metadata": {
        "id": "jnlbyuS81IJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.describe()"
      ],
      "metadata": {
        "id": "jROFPFyh1UVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change state holiday value a,b,c is equal to 1\n",
        "sales_df['StateHoliday'].value_counts()"
      ],
      "metadata": {
        "id": "-pMrryiO1Uwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change datatype object into date format \n",
        "sales_df['Date'].unique()"
      ],
      "metadata": {
        "id": "ZEEid5kE1Vh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.isnull().sum()"
      ],
      "metadata": {
        "id": "z732Nc289R8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.info()"
      ],
      "metadata": {
        "id": "ThAzZ5GT1VwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-Data Wrangling**"
      ],
      "metadata": {
        "id": "MEYzNioGEUJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "P9DPcEweEUid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TqmVacc4dgeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CompetitionDistance - distance in meters to the nearest competitor store\n",
        "\n",
        "sales_df['SchoolHoliday'] .unique()"
      ],
      "metadata": {
        "id": "TtGMW-zb4l0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "ecByvEs89ljQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "li = [\"DayOfWeek\" , \"StateHoliday\" , \"SchoolHoliday\"]\n",
        "\n",
        "for i in li:\n",
        "  print(i)\n",
        "  print(sales_df[i].unique())\n",
        "  print(\"-----------------------\")\n",
        "     "
      ],
      "metadata": {
        "id": "Ir3Drwvc4mDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.nunique()"
      ],
      "metadata": {
        "id": "nt7AyPkQ4mUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STORE DATASET FILL INTO NULL VALUES I.E 0\n",
        "store_df['CompetitionDistance'] = store_df['CompetitionDistance'].fillna(0)\n",
        "store_df['CompetitionOpenSinceMonth'] = store_df['CompetitionOpenSinceMonth'].fillna(0)\n",
        "store_df['CompetitionOpenSinceYear'] = store_df['CompetitionOpenSinceYear'].fillna(0)\n",
        "store_df['Promo2SinceWeek'] = store_df['Promo2SinceWeek'].fillna(0)\n",
        "store_df['Promo2SinceYear'] = store_df['Promo2SinceYear'].fillna(0)\n",
        "store_df['PromoInterval'] = store_df['PromoInterval'].fillna(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "Pc9T3byKE8L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.isna().sum()"
      ],
      "metadata": {
        "id": "c53xQXDqOj5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df"
      ],
      "metadata": {
        "id": "HVnSd3-rE8m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1 = pd.merge(sales_df, store_df, on='Store', how='left')"
      ],
      "metadata": {
        "id": "VuCENkPgOFO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1"
      ],
      "metadata": {
        "id": "dKZ_7H9cPWxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change data types object to int \n",
        "final1.loc[final1['StateHoliday'] == '0', 'StateHoliday'] = 0\n",
        "final1.loc[final1['StateHoliday'] == 'a', 'StateHoliday'] = 1\n",
        "final1.loc[final1['StateHoliday'] == 'b', 'StateHoliday'] = 2\n",
        "final1.loc[final1['StateHoliday'] == 'c', 'StateHoliday'] = 3\n",
        "#store the value with same column name i.e StateHoliday with function astype\n",
        "final1['StateHoliday'] = final1['StateHoliday'].astype(int, copy=False)"
      ],
      "metadata": {
        "id": "jPDM3PQdywKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change Data Types object into int \n",
        "final1.loc[final1['Assortment'] == 'a', 'Assortment'] = 0\n",
        "final1.loc[final1['Assortment'] == 'b', 'Assortment'] = 1\n",
        "final1.loc[final1['Assortment'] == 'c', 'Assortment'] = 2\n",
        "#store the value with same column name i.e Assortment with function astype\n",
        "final1['Assortment'] = final1['Assortment'].astype(int, copy=False)"
      ],
      "metadata": {
        "id": "6uWEPlsK4fdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change Data Types object into int \n",
        "final1.loc[final1['StoreType'] == 'a', 'StoreType'] = 0\n",
        "final1.loc[final1['StoreType'] == 'b', 'StoreType'] = 1\n",
        "final1.loc[final1['StoreType'] == 'c', 'StoreType'] = 2\n",
        "final1.loc[final1['StoreType'] == 'd', 'StoreType'] = 3\n",
        "#store the value with same column name i.e Assortment with function astype\n",
        "final1['StoreType'] = final1['StoreType'].astype(int, copy=False)"
      ],
      "metadata": {
        "id": "asDhmvtj4ftX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final1[['StateHoliday', 'Assortment', 'StoreType']].nunique())"
      ],
      "metadata": {
        "id": "B5y8MCea83yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1.info()"
      ],
      "metadata": {
        "id": "T7e15OeC_Daf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " final1[\"Sales\"].value_counts()"
      ],
      "metadata": {
        "id": "1jGUiHWPfo4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for changing format of date from object to datetime\n",
        "final1['Date'] = pd.to_datetime(final1['Date'], format= '%Y-%m-%d')"
      ],
      "metadata": {
        "id": "o-r1sBjpBy7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for change object into date format\n",
        "final1['CompetitionOpenSinceMonth'] = pd.DatetimeIndex(final1['Date']).month"
      ],
      "metadata": {
        "id": "2fEiBxYfBztl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for change float into integer \n",
        "final1['CompetitionOpenSinceYear']= final1['CompetitionOpenSinceYear'].astype(int)\n",
        "final1['Promo2SinceYear']= final1['Promo2SinceYear'].astype(int)\n"
      ],
      "metadata": {
        "id": "Zzwd1OK3EDmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for change float into integer \n",
        "final1['CompetitionDistance']= final1['CompetitionDistance'].astype(int)\n",
        "final1['Promo2SinceWeek']= final1['Promo2SinceWeek'].astype(int)"
      ],
      "metadata": {
        "id": "21LIiYm-EEGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1.info()"
      ],
      "metadata": {
        "id": "UCo_Ka9sEEVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-Understanding Your Variables**"
      ],
      "metadata": {
        "id": "vRxGVLncFkog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final1.head()"
      ],
      "metadata": {
        "id": "3QFngcL7Fob8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1.describe().apply(lambda x: round(x, 2))"
      ],
      "metadata": {
        "id": "gigdZdYFFoyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables**"
      ],
      "metadata": {
        "id": "Zs-MbHuwdm0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales"
      ],
      "metadata": {
        "id": "QWTvLInGIRdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Line chart**"
      ],
      "metadata": {
        "id": "VZXS0J6PXsyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x= 'CompetitionOpenSinceYear', y= 'Sales', data=final1,color='Red')\n",
        "sns.set_style(\"dark\")\n",
        "plt.title('Plot between Sales and Competition Open Since year')"
      ],
      "metadata": {
        "id": "Eo7X6aIHFpyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**From this chart we get insights that Sales is Highest During the Year 1900 because for that time there are limited number of Stores ,hence the competition is very low. But as year pass,no of stores get increased that means Competition also increased accordignly ,hence Sales got Decline year by year.** "
      ],
      "metadata": {
        "id": "NjL846NAeA79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x= 'Promo2SinceYear', y= 'Sales', data=final1,color='Red')\n",
        "sns.set_style(\"dark\")\n",
        "plt.title('Plot between Sales and Promo2SinceYear')\n"
      ],
      "metadata": {
        "id": "BRx2SbtYFqKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**From This Graph We saw that sales of  stores  is effected which continues their promotion.The Sales in 2013 and 2015 are very low inspite of promotion.The reason can be more competiton year by year.**"
      ],
      "metadata": {
        "id": "iIXDJlNijg3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x= 'DayOfWeek', y= 'Sales', data=final1,color='Red')\n",
        "sns.set_style(\"dark\")\n",
        "plt.title('Plot between Sales and DayOfWeek')"
      ],
      "metadata": {
        "id": "HB0908uSVkST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**From this graph we get insights that Maximum Sales is on Day 1 which is Monday and the same  is decreasing till Day 6 which is Saturday .As most of the stores are closed on Day 7 which is Sunday ,so the Sales is closed to Zero.**\n"
      ],
      "metadata": {
        "id": "TrOVG4UHlgMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x= 'CompetitionOpenSinceMonth', y= 'Sales', data=final1,color='Red')\n",
        "sns.set_style(\"dark\")\n",
        "plt.title('Plot between Sales and CompetitionOpenSinceMonth ')"
      ],
      "metadata": {
        "id": "tKqfSXNUMWg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BOX PLOT**"
      ],
      "metadata": {
        "id": "SBA56386XkOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 11))\n",
        "plot_storetype_sales = sns.boxplot(x=\"StoreType\", y=\"Sales\", data=final1, saturation=1.5,width=0.8)\n",
        "plt.title('Boxplot For Sales Values')"
      ],
      "metadata": {
        "id": "C5LyKwQuX43_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 11))\n",
        "plot_storetype_sales = sns.boxplot(x=\"Assortment\", y=\"Sales\", data=final1, saturation=1.5,width=0.8)\n",
        "plt.title('Boxplot For Sales Values on the basis of Assortment')"
      ],
      "metadata": {
        "id": "s10C91d-X51K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "sns.countplot(x= 'DayOfWeek', hue='Open', data= final1, palette='viridis')\n",
        "plt.title('Store Daily Open Countplot')\n"
      ],
      "metadata": {
        "id": "mcBHZQtxX6DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "sns.countplot(x= 'DayOfWeek', hue='Promo', data= final1, palette='viridis')\n",
        "plt.title('Store Daily Promo Countplot')"
      ],
      "metadata": {
        "id": "_NhEeqfwX6Ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "promo_sales = sns.barplot(x=\"Promo\", y=\"Sales\", data=final1, palette='viridis')"
      ],
      "metadata": {
        "id": "D-UtTXAvX6LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here 0 represents the store which didnt opt for promotion and 1 represents for stores who opt for promotion. Those store who took promotions their sales are high as compared to stores who didnt took promotion.**"
      ],
      "metadata": {
        "id": "kPDZqtCjnDrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **State Holiday**\n",
        "\n",
        "**0 = public holiday, 1 = Easter holiday, 2 = Christmas, 3 = None**"
      ],
      "metadata": {
        "id": "5QLc-28ClSH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "stateholiday_sales = sns.barplot(x=\"StateHoliday\", y=\"Sales\", data=final1,palette='viridis')"
      ],
      "metadata": {
        "id": "rgkHEICrX6OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **School Holiday**\n",
        "\n",
        "**0='Not Holiday', 1='Holiday'**"
      ],
      "metadata": {
        "id": "vssQQ8sjoc45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "stateholiday_sales = sns.barplot(x=\"SchoolHoliday\", y=\"Sales\", data=final1,palette='viridis')"
      ],
      "metadata": {
        "id": "SXjVPoMpX6Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can observe that most of the stores remain closed during State and Holidays. But it is interesting to note that the number of stores opened during School Holidays were more than that were opened during State Holidays. Another important thing to note is that the stores which were opened during School holidays had more sales than normal.**"
      ],
      "metadata": {
        "id": "zKv8xwk1ndk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion of EDA**\n",
        "\n",
        "\n",
        "\n",
        "1)From plot sales and competition Open Since Month shows sales go increasing from November and highest in month December.\n",
        "\n",
        "2)From plot Sales and day of week, Sales highest on Monday and start declining from Tuesday to Saturday and on Sunday Sales almost near to Zero.\n",
        "\n",
        "3)Plot between Promotion and Sales shows that promotion helps in increasing Sales.\n",
        "\n",
        "4)Type of Store plays an important role in opening pattern of stores.\n",
        "\n",
        "5)All Type ‘b’ stores never closed except for refurbishment or other reason.\n",
        "\n",
        "6)All Type ‘b’ stores have comparatively higher sales and it mostly constant with peaks appears on weekends.\n",
        "\n",
        "7)ssortment Level ‘b’ is only offered at Store Type ‘b’.\n",
        "\n",
        "\n",
        "8)We can observe that most of the stores remain closed during State Holidays. But it is interesting to note that the number of stores opened during School Holidays were more than that were opened during State Holidays."
      ],
      "metadata": {
        "id": "_pUBoj4cLMtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6-Feature Engineering & Data Pre-processing**"
      ],
      "metadata": {
        "id": "3oi4tQYrfykN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "correlation = final1.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='Reds',linewidths=2,fmt=\".2f\")"
      ],
      "metadata": {
        "id": "W5fYteMvTolP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multicollinearity**"
      ],
      "metadata": {
        "id": "jZ342OS_cXbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "dhyxSXCdToqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(final1[[i for i in final1.describe().columns if i not in ['Sales']]])"
      ],
      "metadata": {
        "id": "rvfILMB6Tou-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In above table we can see that VIF(Variance Inflation Factor) value for column Promo2 and Promo2SinceYear is Higher .So we will drop either Promo2 or Promo2SinceYear and again check VIF value.Here we drop Promo2 column.**"
      ],
      "metadata": {
        "id": "8jrLKgQBgQbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(final1[[i for i in final1.describe().columns if i not in ['Sales','Promo2']]])"
      ],
      "metadata": {
        "id": "zRbeij2xTozI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VIF factor below 10 is look good for Machine Learning Model.**"
      ],
      "metadata": {
        "id": "JRpUmXxSiXs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analysis of Target Variable i.e 'Sales'.**"
      ],
      "metadata": {
        "id": "Pf5O5o5MiIp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(final1['Sales'],).hist(bins=5, color=\"red\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AD027j-uX6UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1[(final1.Open == 0) & (final1.Sales == 0)].count()[0]"
      ],
      "metadata": {
        "id": "l7D6gbBsj1Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**So we will drop thoose store which sales is 0 assuming that the stores were closed temoprarily and this will help to train the model more accurately.**"
      ],
      "metadata": {
        "id": "9-WzZO2OkEZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = final1.drop(final1[(final1.Open == 0) & (final1.Sales == 0)].index)"
      ],
      "metadata": {
        "id": "JNnPVnX8k6xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.shape"
      ],
      "metadata": {
        "id": "zrkVUB0jk7Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df"
      ],
      "metadata": {
        "id": "YPZNWQezk7a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**In new_df dataset,column name 'PromoInterval' change into dummies it means that each new column will have a binary value (0 or 1).**"
      ],
      "metadata": {
        "id": "wC8dJ3JKnjgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.get_dummies(new_df, columns=['PromoInterval'])\n"
      ],
      "metadata": {
        "id": "y63Y_w6ong0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df"
      ],
      "metadata": {
        "id": "qruJ_iUNomRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv('cleandata.csv', index=False)"
      ],
      "metadata": {
        "id": "mS15jRsCcNca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5-Hypothesis Testing**"
      ],
      "metadata": {
        "id": "_gZHzpo7d5YE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothetical Statement - 1**\n",
        "\n",
        "# **MODEL 1 (excluding rows which has sales =0)**"
      ],
      "metadata": {
        "id": "ZGpm1MI5eYrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hypothetical Statement - 2**\n",
        "\n",
        "# **MODEL 2 (By taking whole Dataset)**"
      ],
      "metadata": {
        "id": "KO2sqVgNfBDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7-ML Model Implementation**"
      ],
      "metadata": {
        "id": "sqFvZKQ4gctj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL TRAINING**"
      ],
      "metadata": {
        "id": "lLkcBJ2qo5CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score as r2, mean_squared_error as mse\n",
        "import math\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "metadata": {
        "id": "H3OspT41pOJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL 1 (excluding rows which has sales =0)**\n",
        "\n",
        "\n",
        "As we have two dataset,first one having sales = '0' rows and another exculding it. We will both the data and find the best model.\n",
        "\n",
        "**First We will take dataset excluding Sales = '0' rows.**"
      ],
      "metadata": {
        "id": "Qx_A1jVpqqWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining dependent variable\n",
        "dependent_variables = 'Sales'\n",
        "\n",
        "# defining independent variable\n",
        "independent_variables = list(new_df.columns.drop(['Promo2SinceYear','Date','Sales']))"
      ],
      "metadata": {
        "id": "UPChISPTqAPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#List of Independent Variable \n",
        "independent_variables\n"
      ],
      "metadata": {
        "id": "M2cVtvjwqAd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data of independent variables\n",
        "X = new_df[independent_variables].values\n",
        "\n",
        "# Create the data of dependent variable\n",
        "y = new_df[dependent_variables].values"
      ],
      "metadata": {
        "id": "45H5AU4YqAj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "psKG9Z0tqAnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we Train the model \n",
        "reg = LinearRegression().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "SwpDtkVzqAqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the Regression Score i.e R-squared value\n",
        "reg.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "ZzuqlSySqAtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the cofficient of different independent columns\n",
        "reg.coef_"
      ],
      "metadata": {
        "id": "FKJX5CzMqAxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the intercept of different indpendent columns\n",
        "reg.intercept_"
      ],
      "metadata": {
        "id": "bGj_KJoUqA08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting Dependent Variable With Test Dataset i.e 20%\n",
        "y_pred = reg.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "P8YZFPluxdKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Original Test Dependent Value\n",
        "y_test"
      ],
      "metadata": {
        "id": "HqsqF4k1xdVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting on Train Dataset\n",
        "y_pred_train = reg.predict(X_train)\n",
        "y_pred_train\n"
      ],
      "metadata": {
        "id": "rHmjDesw0_G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependent Variable With Train Dataset i.e 80 %\n",
        "y_train"
      ],
      "metadata": {
        "id": "uiaEXPZH1SFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate MSE & RMSE for Test Prediction\n",
        "MSE  = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)"
      ],
      "metadata": {
        "id": "D7evuM3L1SM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "_Sm32kSb1Snh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(zip(y_test, y_pred), columns = ['actual', 'pred'])"
      ],
      "metadata": {
        "id": "yviWgHhDeuO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n"
      ],
      "metadata": {
        "id": "DGrWYVWl927E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lime"
      ],
      "metadata": {
        "id": "tVmvUOLC_Okx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SHAP and LIME**"
      ],
      "metadata": {
        "id": "5HImvUoYa5q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "# load the Rossman dataset\n",
        "data = pd.read_csv(\"/content/cleandata.csv\", low_memory=False)\n",
        "\n",
        "# convert the 'Date' column to datetime format\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "# extract year, month, and day of week from 'Date' column\n",
        "data['Year'] = data['Date'].dt.year\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "\n",
        "# select relevant features\n",
        "features = ['Store', 'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday', 'Year', 'Month']\n",
        "\n",
        "\n",
        "\n",
        "# split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data['Sales'], test_size=0.2, random_state=42)\n",
        "\n",
        "# create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# create a SHAP explainer object\n",
        "explainer = shap.LinearExplainer(model, X_train, feature_dependence=\"independent\")\n",
        "\n",
        "# calculate SHAP values for the test set\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# plot the SHAP values for the first feature of the first test instance\n",
        "shap.summary_plot(shap_values, X_test, feature_names=X_test.columns)\n",
        "\n",
        "# create a LIME explainer object\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns, class_names=['Sales'], mode='regression')\n",
        "\n",
        "# explain the prediction for the first test instance using LIME\n",
        "exp = explainer.explain_instance(X_test.values[0], model.predict, num_features=4)\n",
        "\n",
        "# print the LIME explanation\n",
        "print(exp.as_list())\n"
      ],
      "metadata": {
        "id": "NQRd6szb-NOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LASSO**"
      ],
      "metadata": {
        "id": "GUQ1h8QCdF8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "L1 = Lasso(alpha = 0.4, max_iter=10000,selection='cyclic', tol=0.0001,)"
      ],
      "metadata": {
        "id": "5Ohta52EctnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L1.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Ptiv05qAct1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lasso = L1.predict(X_test)"
      ],
      "metadata": {
        "id": "eXpBRpkqeCxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L1.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "yScYw4LceD-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores = cross_val_score(L1, X, y, cv=10)\n",
        "mean_cv_score = cv_scores.mean()"
      ],
      "metadata": {
        "id": "DWmVX8aGhXjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores"
      ],
      "metadata": {
        "id": "XzClU0cmiIED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_cv_score"
      ],
      "metadata": {
        "id": "E1UrPY8Nip8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "# define the range of alpha values to test\n",
        "parameters = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5]}\n",
        "\n",
        "# perform grid search to find the best alpha value\n",
        "lasso_cv = GridSearchCV(L1, parameters, cv=5)\n",
        "lasso_cv.fit(X, y)\n",
        "\n"
      ],
      "metadata": {
        "id": "nzUdTGIHkFBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the best alpha value and corresponding score\n",
        "best_alpha_lasso = lasso_cv.best_params_['alpha']\n",
        "best_score_lasso= lasso_cv.best_score_"
      ],
      "metadata": {
        "id": "6_bvHPY2lDwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_alpha_lasso"
      ],
      "metadata": {
        "id": "ju3jqxonlpaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_score_lasso"
      ],
      "metadata": {
        "id": "Xc_nVw1Rl6ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(zip(y_test, y_pred_lasso), columns = ['actual', 'pred'])"
      ],
      "metadata": {
        "id": "I-kpT64teEbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge**"
      ],
      "metadata": {
        "id": "yZAyq-SnjTHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L2 = Ridge(alpha = 0.5)"
      ],
      "metadata": {
        "id": "7cSBzT6ReEhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "FJ_2lFTteFCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2.predict(X_test)"
      ],
      "metadata": {
        "id": "K_vpSNYoeFHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2.score(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "WHu76t-dcuHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "ridge = Ridge(max_iter=10000, solver='auto')\n",
        "\n",
        "# define the range of alpha values to test\n",
        "parameters = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5]}\n",
        "\n",
        "# perform grid search to find the best alpha value\n",
        "ridge_cv = GridSearchCV(L2, parameters, cv=5)\n",
        "ridge_cv.fit(X, y)\n",
        "\n",
        "# extract the best alpha value and corresponding score\n",
        "best_alpha = ridge_cv.best_params_['alpha']\n",
        "best_score = ridge_cv.best_score_\n",
        "\n",
        "# perform cross-validation with the best alpha value\n",
        "ridge_best = Ridge(alpha=best_alpha, max_iter=10000, solver='auto')\n",
        "cv_scores = cross_val_score(ridge_best, X, y, cv=5)\n",
        "\n",
        "# find the maximum score and corresponding alpha value\n",
        "max_score = cv_scores.max()\n",
        "max_alpha = best_alpha\n",
        "\n",
        "print(\"Best alpha value: \", best_alpha)\n",
        "print(\"Best score: \", best_score)\n",
        "print(\"Maximum CV score: \", max_score)\n",
        "print(\"Corresponding alpha value: \", max_alpha)\n"
      ],
      "metadata": {
        "id": "p-rHS3RPnqQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Elastic Net**"
      ],
      "metadata": {
        "id": "LHGhG9c0tLPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# define the Elastic Net model\n",
        "elastic_net = ElasticNet(max_iter=10000)\n",
        "\n",
        "# define the range of alpha and l1_ratio values to test\n",
        "parameters = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5], 'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]}\n",
        "\n",
        "# perform grid search to find the best alpha and l1_ratio values\n",
        "elastic_net_cv = GridSearchCV(elastic_net, parameters, cv=5)\n",
        "elastic_net_cv.fit(X_train, y_train)\n",
        "\n",
        "# extract the best alpha and l1_ratio values and corresponding score\n",
        "best_alpha = elastic_net_cv.best_params_['alpha']\n",
        "best_l1_ratio = elastic_net_cv.best_params_['l1_ratio']\n",
        "best_score = elastic_net_cv.best_score_\n",
        "\n",
        "# create an Elastic Net model with the best hyperparameters\n",
        "elastic_net_best = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio, max_iter=10000)\n",
        "elastic_net_best.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the model on the testing set\n",
        "test_score = elastic_net_best.score(X_test, y_test)\n",
        "\n",
        "print(\"Best alpha value: \", best_alpha)\n",
        "print(\"Best l1_ratio value: \", best_l1_ratio)\n",
        "print(\"Best score: \", best_score)\n",
        "print(\"Test score: \", test_score)\n"
      ],
      "metadata": {
        "id": "Ti7oZbGEsPQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree**"
      ],
      "metadata": {
        "id": "Jp-8LvUNqSvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_mean=final1[dependent_variables].mean()"
      ],
      "metadata": {
        "id": "o4hi9fI5r1_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_mean"
      ],
      "metadata": {
        "id": "hLjhu1bDsJym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sales_mean_new=new_df[dependent_variables].mean()"
      ],
      "metadata": {
        "id": "Cb9Biv-AsN6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_mean_new"
      ],
      "metadata": {
        "id": "LrmN4QuwsSu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree=DecisionTreeRegressor(max_depth=5)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "y_train_dt = decision_tree.predict(X_train)\n",
        "#print('dt_regressor R^2: ', r2(v_test,v_pred))\n",
        "MSE  = mean_squared_error(y_test, y_pred_dt)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_mean_new\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_dt)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "3JrVwNxeqZHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL 2 (By taking whole Dataset)**\n",
        "\n",
        "\n",
        "**In final1 dataset,column name 'PromoInterval' change into dummies it means that each new column will have a binary value (0 or 1).**"
      ],
      "metadata": {
        "id": "03OdlsELuJho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final1 = pd.get_dummies(final1, columns=['PromoInterval'])"
      ],
      "metadata": {
        "id": "yVh1AdI9qZcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1.head()"
      ],
      "metadata": {
        "id": "AY5a7_rnqZnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We define dependent and independent variables and convert them into arrays**"
      ],
      "metadata": {
        "id": "lz7leFZcvd3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining dependent variable\n",
        "dep_var = 'Sales'\n",
        "\n",
        "# defining independent variable\n",
        "indep_var = final1.columns.drop(['Store', 'Promo2SinceYear','Date','Sales'])"
      ],
      "metadata": {
        "id": "SwakgsBXqZzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indep_var"
      ],
      "metadata": {
        "id": "hr4Kv70Jv_4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data of independent variables\n",
        "U = final1[indep_var].values\n",
        "# Create the dependent variable data\n",
        "V = final1[dep_var].values"
      ],
      "metadata": {
        "id": "iO27cebrwAY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V "
      ],
      "metadata": {
        "id": "bXIgsa_Bx0z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U"
      ],
      "metadata": {
        "id": "HJzEDXmex0-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1[indep_var]"
      ],
      "metadata": {
        "id": "Ja_dkNIvyF6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset\n",
        "U_train, U_test, v_train, v_test = train_test_split(U, V, test_size=0.2, random_state = 0)\n",
        "print(U_train.shape)\n",
        "print(U_test.shape)"
      ],
      "metadata": {
        "id": "GBm7rtwNzA6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LINEAR REGRESSION**"
      ],
      "metadata": {
        "id": "CmiMQ1cD1yCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scling the x values\n",
        "scaler=StandardScaler()\n",
        "\n",
        "U_train = scaler.fit_transform(U_train)\n",
        "U_test = scaler.transform(U_test)"
      ],
      "metadata": {
        "id": "2GVmjFQw1t2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the data into Lineat Regression Model\n",
        "linear_regression = LinearRegression()\n",
        "linear_regression.fit(U_train, v_train)"
      ],
      "metadata": {
        "id": "jqAmRVah1uPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_pred=linear_regression.predict(U_test)\n",
        "v_pred"
      ],
      "metadata": {
        "id": "3d8Boept1upT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression.score(U_train, v_train)"
      ],
      "metadata": {
        "id": "Ngg7UE3C4Czf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regression_Dataframe = pd.DataFrame(zip(v_test, v_pred), columns = ['actual', 'pred'])\n",
        "regression_Dataframe\n"
      ],
      "metadata": {
        "id": "iXWZZ80h4K68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "MSE  = mean_squared_error(v_test, v_pred)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_mean\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "qFoEZLpW40Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DECISION TREE**"
      ],
      "metadata": {
        "id": "qMimlQ9B6Dfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree=DecisionTreeRegressor(max_depth=5)\n",
        "decision_tree.fit(U_train, v_train)\n",
        "v_pred_dt = decision_tree.predict(U_test)\n",
        "v_train_dt = decision_tree.predict(U_train)\n",
        "#print('dt_regressor R^2: ', r2(v_test,v_pred))\n",
        "MSE  = mean_squared_error(v_test, v_pred_dt)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_mean\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_dt)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "wBUs6Wej59rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decisiontree_Dataframe = pd.DataFrame(zip(v_test, v_pred_dt), columns = ['actual', 'pred'])\n",
        "decisiontree_Dataframe\n"
      ],
      "metadata": {
        "id": "ywHi2ldp6caS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Create a random forest regressor with n_estimators=500, max_depth=8, and n_jobs=2\n",
        "random_forest = RandomForestRegressor(n_estimators=500, max_depth=8, n_jobs=2)\n",
        "\n",
        "# Fit the random forest to the training data\n",
        "random_forest.fit(U_train, v_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "v_pred_rf = random_forest.predict(U_test)\n",
        "\n",
        "# Calculate the mean squared error (MSE) between the predicted and actual values\n",
        "MSE = mean_squared_error(v_test, v_pred_rf)\n",
        "print(\"MSE:\", MSE)\n",
        "\n",
        "# Calculate the root mean squared error (RMSE)\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE:\", RMSE)\n",
        "\n",
        "# Calculate the root mean squared percentage error (RMPSE)\n",
        "sales_mean = np.mean(v_test)\n",
        "RMPSE = RMSE / sales_mean\n",
        "print(\"RMPSE:\", RMPSE)\n",
        "\n",
        "# Calculate the coefficient of determination (R2 score)\n",
        "r2 = r2_score(v_test, v_pred_rf)\n",
        "print(\"R2:\", r2)\n"
      ],
      "metadata": {
        "id": "blxyhad77c5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "adaboost = AdaBoostRegressor(n_estimators=500, learning_rate=0.01)\n",
        "adaboost.fit(U_train, v_train)\n",
        "v_pred_ada = adaboost.predict(U_test)\n",
        "\n",
        "MSE = mean_squared_error(v_test, v_pred_ada)\n",
        "print(\"MSE :\", MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\", RMSE)\n",
        "\n",
        "RMPSE = RMSE/sales_mean\n",
        "print(\"RMPSE :\", RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_ada)\n",
        "print(\"R2 :\", r2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EUa0f_9LOoRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgboost = xgb.XGBRegressor(n_estimators=500, max_depth=8, n_jobs=2)\n",
        "xgboost.fit(U_train, v_train)\n",
        "v_pred_xgb = xgboost.predict(U_test)\n",
        "\n",
        "MSE = mean_squared_error(v_test, v_pred_xgb)\n",
        "print(\"MSE :\", MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\", RMSE)\n",
        "\n",
        "RMPSE = RMSE/sales_mean\n",
        "print(\"RMPSE :\", RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_xgb)\n",
        "print(\"R2 :\", r2)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jFRTuHpUKMxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saw that Sales column contains 172817 rows with 0 sale. So we created a   new dataframe in which we removed 0 sales rows and tried to train our model. We used various algorithms and got accuracy score around **74%.**\n",
        "\n",
        "\n",
        "\n",
        "We were also curious about the total dataset(including Sales = 0 rows). So we trained another model using various algorithms and we got accuracy near about **98%** which is far better than previous model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "So we came to conclusion that removing sales=0 rows actually removes lot of information from dataset as it has **172817**   rows which is quite large and therefore we decided not to remove those values.We got our best rmpse score from **Random Forest model,Graident boosting technique like  adaboost ,Xgboost**,we tried taking an optimum parameter so that our model doesnt overfit.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}